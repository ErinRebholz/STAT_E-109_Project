---
title: "STAT_E-109_Project"
author: "Erin Rebholz, Nadia Zafar, Imran Naskani, Max Yanover"
output: html_document
date: "2023-03-22"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Intitial package installation and data loading

```{r, packages}

#Install packages/libraries

library(dplyr)
library(ggplot2)
library(psych)
library(gridExtra)
library(PerformanceAnalytics)
library(olsrr)
library(caret)
library(nnet)
```

```{r, load}

#Load in csv data for project

data <- read.csv('SDOH_Quality.csv')

#count_initial <- nrow(data)

#str(data)

```

```{r}


#Switch to numeric variables fo censuse/SDOH measures

data$median_age <- as.numeric(data$median_age)
data$per_white_non_hisp <- as.numeric(data$per_white_non_hisp)
data$med_inc_15plus_12mo <- as.numeric(data$med_inc_15plus_12mo)
data$per_below_poverty <- as.numeric(data$per_below_poverty)
data$per_college_grad_deg_25_plus <- as.numeric(data$per_college_grad_deg_25_plus)
          
#Switch to numeric variables for quality measures
data$COMP_HIP_KNEE <- as.numeric(data$COMP_HIP_KNEE)
data$MORT_30_AMI <- as.numeric(data$MORT_30_AMI)
data$MORT_30_CABG <- as.numeric(data$MORT_30_CABG)
data$MORT_30_COPD <- as.numeric(data$MORT_30_COPD)
data$MORT_30_HF <- as.numeric(data$MORT_30_HF)
data$MORT_30_PN <- as.numeric(data$MORT_30_PN)
data$MORT_30_STK <- as.numeric(data$MORT_30_STK)
data$PSI_03 <- as.numeric(data$PSI_03)
data$PSI_04 <- as.numeric(data$PSI_04)
data$PSI_06 <- as.numeric(data$PSI_06)
data$PSI_08 <- as.numeric(data$PSI_08)
data$PSI_09 <- as.numeric(data$PSI_09)
data$PSI_10 <- as.numeric(data$PSI_10)
data$PSI_12 <- as.numeric(data$PSI_12)
data$PSI_11 <- as.numeric(data$PSI_11)
data$PSI_13 <- as.numeric(data$PSI_13)
data$PSI_11 <- as.numeric(data$PSI_11)
data$PSI_14 <- as.numeric(data$PSI_14)
data$PSI_15 <- as.numeric(data$PSI_15)
data$PSI_90 <- as.numeric(data$PSI_90)

#Switch chr variables to factor
data$city <- as.factor(data$city)
data$state <- as.factor(data$state)
data$hospital_type <- as.factor(data$hospital_type)
data$hospital_ownership <- as.factor(data$hospital_ownership)
data$census_region <- as.factor(data$census_region)
data$census_division <- as.factor(data$census_division)

#check to make sure all are now integers
#str(data)
#View(data)
```

```{r}

#EDA on Star Rating v/s Hospital Types and Ownership

#------- Summarising Avg, SD and Median per Hospital Type -------------
data %>% filter(!is.na(hosp_overall_rating)) %>%  group_by(hospital_type) %>%  
summarise(AVG  = mean(hosp_overall_rating), SD = sd(hosp_overall_rating), Median = median(hosp_overall_rating), COUNT = n()) %>% arrange(desc(AVG))

#------- Box plot: Median per Hospital Type -------------
data %>% filter(!is.na(hosp_overall_rating)) %>%  
  ggplot(aes(x = hospital_type, y = hosp_overall_rating, fill = hospital_type )) + geom_boxplot(show.legend = F)

#------- Summarising Avg, SD and Median per Hospital Type & Ownership ----------
avg.hosp.own <- 
data %>% filter(!is.na(hosp_overall_rating)) %>%  group_by(hospital_type, hospital_ownership) %>% 
summarize(AVG  = round(mean(hosp_overall_rating),2), SD = round(sd(hosp_overall_rating),2), Median = median(hosp_overall_rating), COUNT = n(), .groups = 'drop') %>% arrange(desc(hospital_type))

#------- Barplots: Avg and Count per Hospital Type & Ownership ----------
plot.avg1 <- avg.hosp.own %>% ggplot(aes(x = hospital_ownership, y = AVG, fill = hospital_ownership)) + 
  geom_col(show.legend = F) +
  facet_wrap(~hospital_type) +
  coord_flip()

plot.cnt1 <- avg.hosp.own %>% ggplot(aes(x = hospital_ownership, y = COUNT, fill = hospital_ownership)) + 
  geom_col(show.legend = F) + 
  facet_wrap(~hospital_type) +
  coord_flip() 

grid.arrange(plot.avg1, plot.cnt1, ncol=1)
grid.avg.hosp.own <- arrangeGrob(plot.avg1, plot.cnt1, ncol=1) 

#------- Star Rating Distribution per Hospital Type -------------
data %>% filter(!is.na(hosp_overall_rating)) %>%  
  ggplot(aes(x = hosp_overall_rating, fill = hospital_type)) + 
  geom_histogram(alpha = 0.5, color = "black") +
  facet_wrap(~hospital_type) + 
  ggtitle("Hospital Star Rating", 'Hospital Type') + 
  theme_bw()

##------- Boxplot: Star Rating vs Social Indicators -------------

#------- Boxplot: Star Rating vs Median Age -------------
social.ind1 <- data %>% filter(!is.na(hosp_overall_rating)) %>% 
ggplot(aes(x = hosp_overall_rating, y = median_age, fill = as.factor(hosp_overall_rating))) + 
geom_boxplot(show.legend = F)  + facet_wrap(~hospital_type)

#------- Boxplot: Star Rating vs Percentage White Population -------------
social.ind2 <- data %>% filter(!is.na(hosp_overall_rating)) %>% 
ggplot(aes(x = hosp_overall_rating, y = per_white_non_hisp, fill = as.factor(hosp_overall_rating))) + 
geom_boxplot(show.legend = F) + facet_wrap(~hospital_type) + 
ylab('White Population %') + xlab("Hospital Overall Rating")

grid.arrange(social.ind1, social.ind2, ncol=1)
grid.social.ind1 <- arrangeGrob(social.ind1, social.ind2, ncol=1) 

#------- Boxplot: Star Rating vs Population Below Poverty -------------
social.ind3 <- data %>% filter(!is.na(hosp_overall_rating)) %>% 
ggplot(aes(x = hosp_overall_rating, y = per_below_poverty, fill = as.factor(hosp_overall_rating))) + 
geom_boxplot(show.legend = F)  + facet_wrap(~hospital_type) + 
ylab('Population Below Poverty %') + xlab("Hospital Overall Rating")

#------- Boxplot: Star Rating vs per_college_grad_deg_25_plus -------------
social.ind4 <- data %>% filter(!is.na(hosp_overall_rating)) %>% 
ggplot(aes(x = hosp_overall_rating, y = per_college_grad_deg_25_plus, fill = as.factor(hosp_overall_rating))) + 
geom_boxplot(show.legend = F)  + facet_wrap(~hospital_type) + 
ylab('College Grad 25 years plus %') + xlab("Hospital Overall Rating")

#------- Boxplot: Star Rating vs med_inc_15plus_12mo -------------
social.ind5 <- data %>% filter(!is.na(hosp_overall_rating)) %>% 
ggplot(aes(x = hosp_overall_rating, y = med_inc_15plus_12mo, fill = as.factor(hosp_overall_rating))) + 
geom_boxplot(show.legend = F) + facet_wrap(~hospital_type) + 
ylab('Median Income > 15k %') + xlab("Hospital Overall Rating")

grid.arrange(social.ind3, social.ind4, social.ind5, ncol=2)
grid.social.ind2 <- arrangeGrob(social.ind3, social.ind4, social.ind5, ncol=2) 

#------- Correlation: Star Rating vs Social Indicators  -------------
cor.data <- data %>% filter(!is.na(hosp_overall_rating)) %>% select(10,13:17) 
cor.data <- cor.data[complete.cases(cor.data),] 
pairs.panels(cor.data)

```
```{r,warnging = FALSE}

#---------------ONLY Heart Failure -----------------

#hf_data <- data %>%  
#  select(4:5,7:17,22) %>% #Narrow to features to use in the model (plus one quality measure)
#  filter(hosp_overall_rating != 'NA') %>% #remove NAs
#  filter(MORT_30_HF != 'NA')  #Remove NAs from measure

#View(data)

hf_data <- data %>%  
  select(10,13:17,22) %>% #Narrow to features to use in the model (plus one quality measure)
  filter(hosp_overall_rating != 'NA') %>% #remove NAs
  filter(MORT_30_HF != 'NA')  #Remove NAs from measure


# treat overall rating as a factor  
hf_data$hosp_overall_rating <- as.factor(hf_data$hosp_overall_rating)

# Re leveling to use 1 as reference for Multinomial Model
hf_data$hosp_overall_rating <- relevel(hf_data$hosp_overall_rating, ref = '1')



# Separate into test/train  
set.seed(1234)
#data partitioning test/train
ind <- sample(2, nrow(hf_data), replace = T, prob=c(0.75,0.25))
hf_train <- hf_data[ind == 1,]
hf_test <- hf_data[ind ==2, ]

#nrow(hf_train)
#View(hf_test)

#-city - state -county -hospital_type -hospital_ownership -census_division - census_region 
# Multinomial Model
model_multi_hf <- multinom(hosp_overall_rating ~ ., data = hf_train)
summary(model_multi_hf)
# 2-tailed z test
z <- summary(model_multi_hf)$coefficients/summary(model_multi_hf)$standard.errors
((1 - pnorm(abs(z), 0, 1)) * 2)

# Predict
p_train <- predict(model_multi_hf, hf_train, type = 'class')

#CM - train data
confusionMatrix(p_train, hf_train$hosp_overall_rating)

#CM - test
p_test <- predict(model_multi_hf, hf_test, type = 'class')
confusionMatrix(p_test, hf_test$hosp_overall_rating)





#model_hf <- glm(hosp_overall_rating~ . -city - state -county -hospital_type -hospital_ownership #-census_division - census_region , data = hf_train, family = 'binomial' )
#summary(model_hf)

```

```{r, warning=FALSE}
#---------------All metrics for Multinomial -----------------

#hf_data <- data %>%  
#  select(4:5,7:17,22) %>% #Narrow to features to use in the model (plus one quality measure)
#  filter(hosp_overall_rating != 'NA') %>% #remove NAs
#  filter(MORT_30_HF != 'NA')  #Remove NAs from measure

#View(data)
#View(hf_data)

hf_data <- data %>%  
  select(10,13:36) %>% #Narrow to features to use in the model (plus one quality measure)
  filter(hosp_overall_rating != 'NA') #%>% 
  #filter(MORT_30_HF != 'NA')  #Remove NAs from measure
hf_data <- hf_data[complete.cases(hf_data),] #Only complete cases

# treat overall rating as a factor  
hf_data$hosp_overall_rating <- as.factor(hf_data$hosp_overall_rating)

# Re leveling to use 1 as reference for Multinomial Model
hf_data$hosp_overall_rating <- relevel(hf_data$hosp_overall_rating, ref = '1')



# Separate into test/train  
set.seed(1234)
#data partitioning test/train
ind <- sample(2, nrow(hf_data), replace = T, prob=c(0.4,0.6))
hf_train <- hf_data[ind == 1,]
hf_test <- hf_data[ind ==2, ]

#nrow(hf_train)
#View(hf_test)

#-city - state -county -hospital_type -hospital_ownership -census_division - census_region 
# Multinomial Model
model_multi_hf <- multinom(hosp_overall_rating ~ .-1, data = hf_train)
summary(model_multi_hf)
# 2-tailed z test
z <- summary(model_multi_hf)$coefficients/summary(model_multi_hf)$standard.errors
((1 - pnorm(abs(z), 0, 1)) * 2)

# Predict
p_train <- predict(model_multi_hf, hf_train, type = 'class')

#CM - train data
confusionMatrix(p_train, hf_train$hosp_overall_rating)

#CM - test
p_test <- predict(model_multi_hf, hf_test, type = 'class')
confusionMatrix(p_test, hf_test$hosp_overall_rating)





#model_hf <- glm(hosp_overall_rating~ . -city - state -county -hospital_type -hospital_ownership #-census_division - census_region , data = hf_train, family = 'binomial' )
#summary(model_hf)
```



```{r, warning = FALSE}

hf_data <- data %>%  
  select(8,10:11,13:17,22) %>% #Narrow to features to use in the model (plus one quality measure)
  filter(hosp_overall_rating != 'NA') %>% #remove NAs
  filter(MORT_30_HF != 'NA')   %>%  #Remove NAs from measure
  filter(census_region != '#N/A')   

L <- 1
aic.vector <- numeric(20)
c.train <- c(0.4,0.5,0.6,0.7,0.8)
c.test <- c(0.6,0.5,0.4,0.3,0.2)
for (i in 2:5)
{
hf_data_log <- hf_data
hf_data_log$hosp_overall_rating <- as.numeric(hf_data_log$hosp_overall_rating)
hf_data_log[hf_data_log$hosp_overall_rating < i,]$hosp_overall_rating <- 0
hf_data_log[hf_data_log$hosp_overall_rating >= i,]$hosp_overall_rating <- 1
hf_data_log$hosp_overall_rating <- as.factor(hf_data_log$hosp_overall_rating)

  for (j in 1:5)
  {
  # Separate into test/train  
  set.seed(1234)
  #data partitioning test/train
  ind <- sample(2, nrow(hf_data_log), replace = T, prob=c(c.train[j],c.test[j]))
  hf_train_log <- hf_data_log[ind == 1,]
  hf_test_log <- hf_data_log[ind ==2, ]

  model_train_log <- glm(hosp_overall_rating ~ ., data = hf_train_log, family = 'binomial' )
  #summary(model_train_log)
  full_model <- model_train_log %>% stepAIC(trace = FALSE)
  aic.vector[L] <- full_model$deviance
  L <- L + 1
  }

}

aic.vector




hf_data_log <- hf_data
hf_data_log$hosp_overall_rating <- as.numeric(hf_data_log$hosp_overall_rating)
hf_data_log[hf_data_log$hosp_overall_rating < 4,]$hosp_overall_rating <- 0
hf_data_log[hf_data_log$hosp_overall_rating >= 4,]$hosp_overall_rating <- 1
hf_data_log$hosp_overall_rating <- as.factor(hf_data_log$hosp_overall_rating)

  # Separate into test/train  
  set.seed(1234)
  #data partitioning test/train
  ind <- sample(2, nrow(hf_data_log), replace = T, prob=c(0.5,0.5))
  hf_train_log <- hf_data_log[ind == 1,]
  hf_test_log <- hf_data_log[ind ==2, ]

  model_train_log <- glm(hosp_overall_rating ~ hospital_type + census_region + 
    per_white_non_hisp + per_below_poverty +  
    MORT_30_HF, data = hf_train_log, family = 'binomial' )
  summary(model_train_log)
  #(full_model <- model_train_log %>% stepAIC(trace = FALSE))



#CM - train data
p_log_train <- predict(model_train_log, hf_train_log, type = 'response')
pred_log_train <- ifelse(p_log_train > 0.5, 1, 0)
confusionMatrix(factor(pred_log_train), factor(hf_train_log$hosp_overall_rating), positive = '1')


#CM - test data
p_log_test <- predict(model_train_log, hf_test_log, type = 'response')
pred_log_test <- ifelse(p_log_test > 0.5, 1, 0)
confusionMatrix(factor(pred_log_test), factor(hf_test_log$hosp_overall_rating), positive = '1')

#ROC Curve
p_log_train <- predict(model_train_log, hf_train_log, type = 'response')
r_train <- multiclass.roc(hf_train_log$hosp_overall_rating, p_log_train, percent = TRUE)
roc_train <- r_train[['rocs']]
r1_train <- roc_train[[1]]


p_log_test <- predict(model_train_log, hf_test_log, type = 'response')
r_test <- multiclass.roc(hf_test_log$hosp_overall_rating, p_log_test, percent = TRUE)
roc_test <- r_test[['rocs']]
r1_test <- roc_test[[1]]

plot.roc(r1_train,col= "red", lwd = 3,
         print.auc = T,
         auc.polygon= T,
         max.auc.polygon = T,
         print.thres = T,
         main = "ROC Curve for Hospital Rating")
plot(r1_test, add = T, col = "blue",  
     print.auc = T,
     lwd = 3, print.thres = T)

coords(r1_train, "best", ret="threshold", transpose = FALSE) 
coords(r1_test, "best", ret="threshold", transpose = FALSE) 

```

```{r, warning=FALSE}
#CM - train data
p_log_train <- predict(model_train_log, hf_train_log, type = 'response')
pred_log_train <- ifelse(p_log_train > 0.5090891, 1, 0)
confusionMatrix(factor(pred_log_train), factor(hf_train_log$hosp_overall_rating), positive = '1')


#CM - test data
p_log_test <- predict(model_train_log, hf_test_log, type = 'response')
pred_log_test <- ifelse(p_log_test > 0.4238041, 1, 0)
confusionMatrix(factor(pred_log_test), factor(hf_test_log$hosp_overall_rating), positive = '1')

#ROC Curve
p_log_train <- predict(model_train_log, hf_train_log, type = 'response')
r_train <- multiclass.roc(hf_train_log$hosp_overall_rating, p_log_train, percent = TRUE)
roc_train <- r_train[['rocs']]
r1_train <- roc_train[[1]]


p_log_test <- predict(model_train_log, hf_test_log, type = 'response')
r_test <- multiclass.roc(hf_test_log$hosp_overall_rating, p_log_test, percent = TRUE)
roc_test <- r_test[['rocs']]
r1_test <- roc_test[[1]]

plot.roc(r1_train,col= "red", lwd = 3,
         print.auc = T,
         auc.polygon= T,
         max.auc.polygon = T,
         print.thres = T,
         main = "ROC Curve for Hospital Rating")
plot(r1_test, add = T, col = "blue",  lwd = 3, print.thres = T)

coords(r1_train, "best", ret="threshold", transpose = FALSE) 
coords(r1_test, "best", ret="threshold", transpose = FALSE) 
```



```{r, warning=FALSE}

##---- Logisitic regression with all measures-----------


#View(data)
#View(hf_data)

hf_data <- data %>%  
  select(10:11,13:36) %>% #Narrow to features to use in the model (plus one quality measure)
  filter(hosp_overall_rating != 'NA') %>% #remove NAs
  filter(MORT_30_HF != 'NA')   %>%  #Remove NAs from measure
  filter(census_region != '#N/A')   

hf_data <- hf_data[complete.cases(hf_data),] #Only complete cases


L <- 1
aic.vector <- numeric(20)
c.train <- c(0.4,0.5,0.6,0.7,0.8)
c.test <- c(0.6,0.5,0.4,0.3,0.2)
for (i in 2:5)
{
hf_data_log <- hf_data
hf_data_log$hosp_overall_rating <- as.numeric(hf_data_log$hosp_overall_rating)
hf_data_log[hf_data_log$hosp_overall_rating < i,]$hosp_overall_rating <- 0
hf_data_log[hf_data_log$hosp_overall_rating >= i,]$hosp_overall_rating <- 1
hf_data_log$hosp_overall_rating <- as.factor(hf_data_log$hosp_overall_rating)

  for (j in 1:5)
  {
  # Separate into test/train  
  set.seed(1234)
  #data partitioning test/train
  ind <- sample(2, nrow(hf_data_log), replace = T, prob=c(c.train[j],c.test[j]))
  hf_train_log <- hf_data_log[ind == 1,]
  hf_test_log <- hf_data_log[ind ==2, ]

  model_train_log <- glm(hosp_overall_rating ~ ., data = hf_train_log, family = 'binomial' )
  #summary(model_train_log)
  full_model <- model_train_log %>% stepAIC(trace = FALSE)
  aic.vector[L] <- full_model$deviance
  L <- L + 1
  }

}

aic.vector



hf_data_log <- hf_data
hf_data_log$hosp_overall_rating <- as.numeric(hf_data_log$hosp_overall_rating)
hf_data_log[hf_data_log$hosp_overall_rating < 4,]$hosp_overall_rating <- 0
hf_data_log[hf_data_log$hosp_overall_rating >= 4,]$hosp_overall_rating <- 1
hf_data_log$hosp_overall_rating <- as.factor(hf_data_log$hosp_overall_rating)

#table(hf_data_log$hosp_overall_rating)

  # Separate into test/train  
  set.seed(1234)
  #data partitioning test/train
  ind <- sample(2, nrow(hf_data_log), replace = T, prob=c(0.6,0.4))
  hf_train_log <- hf_data_log[ind == 1,]
  hf_test_log <- hf_data_log[ind ==2, ]

  model_train_log <- glm(hosp_overall_rating ~ census_region + median_age + 
    per_white_non_hisp + per_below_poverty + COMP_HIP_KNEE + 
    MORT_30_AMI + MORT_30_CABG + MORT_30_COPD + MORT_30_PN + 
    MORT_30_STK + PSI_03 + PSI_04 + PSI_06 + PSI_08 + PSI_13, data = hf_train_log, family = 'binomial' )
  summary(model_train_log)
  (full_model <- model_train_log %>% stepAIC(trace = FALSE))



#CM - train data
p_log_train <- predict(model_train_log, hf_train_log, type = 'response')
pred_log_train <- ifelse(p_log_train > 0.5, 1, 0)
confusionMatrix(factor(pred_log_train), factor(hf_train_log$hosp_overall_rating), positive = '1')


#CM - test data
p_log_test <- predict(model_train_log, hf_test_log, type = 'response')
pred_log_test <- ifelse(p_log_test > 0.5, 1, 0)
confusionMatrix(factor(pred_log_test), factor(hf_test_log$hosp_overall_rating), positive = '1')

#ROC Curve
p_log_train <- predict(model_train_log, hf_train_log, type = 'response')
r_train <- multiclass.roc(hf_train_log$hosp_overall_rating, p_log_train, percent = TRUE)
roc_train <- r_train[['rocs']]
r1_train <- roc_train[[1]]


p_log_test <- predict(model_train_log, hf_test_log, type = 'response')
r_test <- multiclass.roc(hf_test_log$hosp_overall_rating, p_log_test, percent = TRUE)
roc_test <- r_test[['rocs']]
r1_test <- roc_test[[1]]

plot.roc(r1_train,col= "red", lwd = 3,
         print.auc = T,
         auc.polygon= T,
         max.auc.polygon = T,
         print.thres = T,
         main = "ROC Curve for Hospital Rating")
plot(r1_test, add = T, col = "blue",  
     print.auc = T,
     lwd = 3, print.thres = T)

coords(r1_train, "best", ret="threshold", transpose = FALSE) 
coords(r1_test, "best", ret="threshold", transpose = FALSE) 
```



```{r, warning=FALSE}

#----- Testing new probability - All measures ------
#CM - train data
p_log_train <- predict(model_train_log, hf_train_log, type = 'response')
pred_log_train <- ifelse(p_log_train > 0.4355048, 1, 0)
confusionMatrix(factor(pred_log_train), factor(hf_train_log$hosp_overall_rating), positive = '1')


#CM - test data
p_log_test <- predict(model_train_log, hf_test_log, type = 'response')
pred_log_test <- ifelse(p_log_test > 0.5119281, 1, 0)
confusionMatrix(factor(pred_log_test), factor(hf_test_log$hosp_overall_rating), positive = '1')

#ROC Curve
p_log_train <- predict(model_train_log, hf_train_log, type = 'response')
r_train <- multiclass.roc(hf_train_log$hosp_overall_rating, p_log_train, percent = TRUE)
roc_train <- r_train[['rocs']]
r1_train <- roc_train[[1]]


p_log_test <- predict(model_train_log, hf_test_log, type = 'response')
r_test <- multiclass.roc(hf_test_log$hosp_overall_rating, p_log_test, percent = TRUE)
roc_test <- r_test[['rocs']]
r1_test <- roc_test[[1]]

plot.roc(r1_train,col= "red", lwd = 3,
         print.auc = T,
         auc.polygon= T,
         max.auc.polygon = T,
         print.thres = T,
         main = "ROC Curve for Hospital Rating")
plot(r1_test, add = T, col = "blue",  lwd = 3, print.thres = T)

coords(r1_train, "best", ret="threshold", transpose = FALSE) 
coords(r1_test, "best", ret="threshold", transpose = FALSE) 
```



```{r, warning=FALSE}
#---- Linear Regression ------

#Data cleaning -> MORT_30_HF - > 30 Day Heart Failure Death Rate

hf_data <- data %>%  
  select(8,10:36) %>% #Narrow to features to use in the model (plus one quality measure)
  filter(hosp_overall_rating != 'NA') %>% #remove NAs
  filter(MORT_30_HF != 'NA')  #Remove NAs from measure

#View(data)
#View(hf_data)

hf_data <- hf_data[complete.cases(hf_data),] #Only complete cases


# treat overall rating as a factor  
hf_data$hosp_overall_rating <- as.factor(hf_data$hosp_overall_rating)

# Separate into test/train  

set.seed(1234)

#data partitioning test/train
ind <- sample(2, nrow(hf_data), replace = T, prob=c(0.6,0.4))

hf_train <- hf_data[ind == 1,]
hf_test <- hf_data[ind ==2, ]

#nrow(hf_train)
#nrow(hf_test)

colnames(hf_data)
#cor.plot(hf_data[,5:28], diag = FALSE, upper = FALSE, cex.axis = 0.5, cex = 0.25)


multi.model <- lm(MORT_30_HF ~ .-1, data = hf_train[,5:28])
summary(multi.model)
vif(multi.model)


multi.model <- lm(MORT_30_HF ~ per_white_non_hisp + COMP_HIP_KNEE + MORT_30_AMI + MORT_30_COPD + MORT_30_PN + MORT_30_STK + PSI_12 - 1
                    , data = hf_train[,5:28])
summary(multi.model)
vif(multi.model)


corrplot(cor(hf_data[,5:28]), 
         type = "upper", 
         method = "number",
         tl.cex = 0.5,
         number.cex = 0.5,
         is.corr = TRUE)


multi.aic <- stepAIC(multi.model)



```